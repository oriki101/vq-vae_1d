{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.vq_vae import VQ_VAE\n",
    "from utils.respiration_datasets import RespirationDataset\n",
    "from utils.respiration_datasets import RespirationDatasetValid\n",
    "from utils.respiration_datasets import RespirationDatasetTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F \n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens = 32\n",
    "num_residual_hiddens = 32\n",
    "num_residual_layers = 2\n",
    "\n",
    "# embedding_dim = 1 #RJS最初\n",
    "embedding_dim = 4\n",
    "num_embeddings = 128\n",
    "\n",
    "commitment_cost = 0.25\n",
    "\n",
    "decay = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_training_updates = 100\n",
    "num_epochs = 500\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RespirationDataset(transform=transforms.ToTensor())\n",
    "valid_dataset = RespirationDatasetValid(transform=transforms.ToTensor())\n",
    "test_dataset = RespirationDatasetTest(transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQ_VAE(num_hiddens, num_residual_layers, num_residual_hiddens,\n",
    "              num_embeddings, embedding_dim, \n",
    "              commitment_cost, decay).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.train()\n",
    "train_res_recon_error = []\n",
    "train_res_perplexity = []\n",
    "recon_error_s = 0\n",
    "res_perplexity = 0\n",
    "data_variance = 1\n",
    "good_id = 0\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, amsgrad=False)\n",
    "\n",
    "f_name = \"respiration_vq_vae-{}-{}dim\".format(num_embeddings, embedding_dim)\n",
    "dt_now = datetime.datetime.now()\n",
    "now = \"{}-{}-{}\".format(dt_now.year, dt_now.month, dt_now.day)\n",
    "name_dir = \"pth/{}\".format(now)\n",
    "name = \"pth/{}/{}.pth\".format(now, f_name)\n",
    "if not os.path.isdir(name_dir):\n",
    "    os.makedirs(name_dir)\n",
    "log_dir = \"logs/{}/{}\".format(now, f_name)\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    recon_error_s = 0\n",
    "    res_perplexity = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        data = data.view(data.size(0), 1, -1)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        vq_loss, data_recon, perplexity = model(data)\n",
    "        recon_error = F.mse_loss(data_recon, data) / data_variance        \n",
    "        loss = recon_error + vq_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        recon_error_s += recon_error.item()\n",
    "        res_perplexity += perplexity.item()\n",
    "        \n",
    "#         recon_error_s += recon_error.item()\n",
    "#         res_perplexity += perplexity.item()\n",
    "        \n",
    "#         # マルチGPU用\n",
    "#         loss = loss.mean()\n",
    "#         #loss.mean().backward()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         perplexity = perplexity.mean()\n",
    "#         recon_error_s += recon_error.item()\n",
    "#         res_perplexity += perplexity.item()\n",
    "    writer.add_scalar(\"train-loss\", recon_error_s/len(train_loader), epoch)\n",
    "    writer.add_scalar(\"train-perplexity\", res_perplexity/len(train_loader), epoch)\n",
    "    \n",
    "    recon_error_s = 0\n",
    "    res_perplexity = 0\n",
    "    #検証データで評価\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in valid_loader:\n",
    "            data = data.to(device, dtype=torch.float)\n",
    "            data = data.view(data.size(0), 1, -1)\n",
    "            vq_loss, data_recon, perplexity = model(data)\n",
    "            recon_error = F.mse_loss(data_recon, data) / data_variance\n",
    "            recon_error_s += recon_error.item()\n",
    "            res_perplexity += perplexity.item()\n",
    "\n",
    "    train_res_recon_error.append(recon_error_s/len(valid_loader))\n",
    "    train_res_perplexity.append(res_perplexity/len(valid_loader))\n",
    "    writer.add_scalar(\"valid-loss\", recon_error_s/len(valid_loader), epoch)\n",
    "    writer.add_scalar(\"valid-perplexity\", res_perplexity/len(valid_loader), epoch)\n",
    "    if recon_error_s/len(train_loader) <= train_res_recon_error[good_id]:\n",
    "        torch.save(model.state_dict(), name)\n",
    "        good_id = epoch\n",
    "\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 復元&食べ物データ確認 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings = 128\n",
    "embedding_dim = 4\n",
    "data_pth = 'pth/2021-9-8/respiration_vq_vae-{}-{}dim.pth'.format(num_embeddings, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQ_VAE(num_hiddens, num_residual_layers, num_residual_hiddens,\n",
    "              num_embeddings, embedding_dim, \n",
    "              commitment_cost, decay).to(device)\n",
    "model.load_state_dict(torch.load(data_pth))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in valid_loader:\n",
    "        data = data.view(data.size(0), 1, -1)\n",
    "        data = data.float()\n",
    "        data = data.to(device)\n",
    "        print(data.shape)\n",
    "        vq_loss, data_recon, perplexity = model(data)\n",
    "#         loss = criterion(net.reconstruction(outputs), data)\n",
    "#         valid_loss += loss.item()\n",
    "        break\n",
    "    \n",
    "axs = []\n",
    "fig = plt.figure()\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(5, 2, i+1)\n",
    "    axs.append(ax)\n",
    "reco = data_recon\n",
    "reco = reco.reshape(-1, data.size(2))\n",
    "t = [i for i in range(data.size(2))]\n",
    "#t = [i for i in range(15000)]\n",
    "for i in range(5):\n",
    "    y1 = reco[i].to('cpu').detach().numpy().copy()\n",
    "    y2 = data[i].to('cpu').detach().numpy().copy()\n",
    "    y2 = y2.reshape(y2.size)\n",
    "\n",
    "    axs[i*2].plot(t, y1, color='blue', label='reconstruction')\n",
    "    axs[i*2+1].plot(t, y2, color='red', label='original')\n",
    "#     axs[i*2].plot(t, y1, color='blue', label='reconstruction')\n",
    "#     axs[i*2+1].plot(t, y2, color='red', label='original')\n",
    "fig.tight_layout()\n",
    "#plt.savefig('1500.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 復元誤差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQ_VAE(num_hiddens, num_residual_layers, num_residual_hiddens,\n",
    "              num_embeddings, embedding_dim, \n",
    "              commitment_cost, decay).to(device)\n",
    "model.load_state_dict(torch.load(data_pth))\n",
    "criterion = nn.MSELoss()\n",
    "model.eval()\n",
    "valid_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in valid_loader:\n",
    "        data = data.view(data.size(0), 1, -1)\n",
    "        data = data.float()\n",
    "        data = data.to(device)\n",
    "        vq_loss, data_recon, perplexity = model(data)\n",
    "        loss = criterion(data_recon, data)\n",
    "        valid_loss += loss.item()\n",
    "valid_loss = valid_loss / len(valid_loader)\n",
    "print(valid_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 食べ物のデータ処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VQ_VAE(num_hiddens, num_residual_layers, num_residual_hiddens,\n",
    "              num_embeddings, embedding_dim, \n",
    "              commitment_cost, decay).to(device)\n",
    "model.load_state_dict(torch.load(data_pth))\n",
    "batch_size = 64\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "valid_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.view(data.size(0), 1, -1)\n",
    "        data = data.float()\n",
    "        data = data.to(device)\n",
    "        z = model._encoder(data)\n",
    "        print(z.shape)\n",
    "        z = model._pre_vq_conv(z)\n",
    "        print(z.shape)\n",
    "        loss, quantized, perplexity, _ = model._vq_vae(z)\n",
    "        break\n",
    "\n",
    "out = quantized.to('cpu').detach().numpy().copy()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 食べ物のデータ処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_id_from_vqvae(model, data):\n",
    "        bsz = data.shape[0]\n",
    "        z = model._pre_vq_conv( model._encoder(data) ) \n",
    "        loss, quantized, perplexity, vq_vae_encodings = model._vq_vae(z)\n",
    "        #token_ids = vq_vae_encodings.argmax(1).view(bsz,-1)\n",
    "        token_ids = vq_vae_encodings.argmax(2).view(bsz,-1)\n",
    "        return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = get_token_id_from_vqvae(model, data)\n",
    "id = id.to('cpu').detach().numpy().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_all = []\n",
    "for i in range(len(id)):\n",
    "    ls = []\n",
    "    for j in range(num_embeddings):\n",
    "        count = 0\n",
    "        for k in range(len(id[0])):\n",
    "            if(id[i][k] == j):\n",
    "                count += 1\n",
    "        ls.append(count)\n",
    "    ls_all.append(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"respiration_VAE_npy/respiration_vq_vae-{}-{}dim\".format(num_embeddings, embedding_dim), ls_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用されているコーパス数を調べる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_flag = [False] * num_embeddings\n",
    "for i in range(len(id)):\n",
    "    for j in range(len(id[i])):\n",
    "        use_flag[id[i][j]] = True\n",
    "\n",
    "use_flag.count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = get_token_id_from_vqvae(model, data)\n",
    "id = id.to('cpu').detach().numpy().copy()\n",
    "corpus = model._vq_vae._embedding.weight\n",
    "corpus = corpus.to('cpu').detach().numpy().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得られたベクトルのコーパスを見て隣接するIDとの類似度を見る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sequence = []\n",
    "all_cos_sequence = []\n",
    "for i in range(len(id)):\n",
    "    cos_sequence = []\n",
    "    for j in range(len(id[i])-1):\n",
    "        sim = cos_sim(corpus[id[i][j]], corpus[id[i][j+1]])\n",
    "        cos_sequence.append(sim)\n",
    "    all_cos_sequence.append(cos_sequence)\n",
    "\n",
    "\n",
    "food = ['pineapple', 'potato', 'ume', 'chocolate']\n",
    "for i in range(len(food)):\n",
    "    sns.heatmap(all_cos_sequence[i*5:(i+1)*5], cmap= sns.color_palette('coolwarm', 10), vmin = -1, vmax = 1)\n",
    "    plt.savefig(\"./fig/test_bvp_{}_day1\".format(food[i]))\n",
    "    plt.clf()\n",
    "    \n",
    "for i in range(len(food)):\n",
    "    sns.heatmap(all_cos_sequence[20+i*3:20+(i+1)*3], cmap= sns.color_palette('coolwarm', 10), vmin = -1, vmax = 1)\n",
    "    plt.savefig(\"./fig/test_bvp_{}_day2\".format(food[i]))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 食べ物のベクトルの類似度を見る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pine1 = ['pineapple 1d{}t'.format(i) for i in range(5)]\n",
    "pine2 = ['pineapple 2d{}t'.format(i) for i in range(3)]\n",
    "potato1 = ['potato 1d{}t'.format(i) for i in range(5)]\n",
    "potato2= ['potato 2d{}t'.format(i) for i in range(3)]\n",
    "ume1=['pickled plums 1d{}t'.format(i) for i in range(5)]\n",
    "ume2=['pickled plums 2d{}t'.format(i) for i in range(3)]\n",
    "chocolate1 = ['chocolate 1d{}t'.format(i) for i in range(5)]\n",
    "chocolate2 = ['chocolate 1d{}t'.format(i) for i in range(3)]\n",
    "\n",
    "index = []\n",
    "index.extend(pine1)\n",
    "index.extend(potato1)\n",
    "index.extend(ume1)\n",
    "index.extend(chocolate1)\n",
    "index.extend(pine2)\n",
    "index.extend(potato2)\n",
    "index.extend(ume2)\n",
    "index.extend(chocolate2)\n",
    "\n",
    "columns = index\n",
    "\n",
    "all_cos_sequence = []\n",
    "for i in range(len(index)):\n",
    "    cos_sequence = []\n",
    "    for j in range(len(index)):\n",
    "        cos_sequence.append(cos_sim(id[i], id[j]))\n",
    "    all_cos_sequence.append(cos_sequence)\n",
    "all_cos_sequence = np.array(all_cos_sequence)\n",
    "df = pd.DataFrame(data=all_cos_sequence, index=index, columns=columns, dtype='float')\n",
    "# print(df)\n",
    "# df.to_excel('gsr_cos_sim.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(all_cos_sequence, cmap= sns.color_palette('coolwarm', 10), vmin = 0, vmax = 1)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoderへの入力のUMAP解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y -c conda-forge umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(ax1, feature, name=None):\n",
    "    #day1\n",
    "    ax.scatter(feature[:5,0],feature[:5,1], c='red', marker='x', label='pineapple day1', s=100)\n",
    "    ax.scatter(feature[5:10,0],feature[5:10,1], c='red',marker='o', label='potato chips day1', s=100)\n",
    "    ax.scatter(feature[10:15,0],feature[10:15,1],  c='blue',marker='^', label='salted plum day1', s=100)\n",
    "    ax.scatter(feature[15:20,0],feature[15:20,1], c='blue',marker='s', label='chocolate day1', s=100)\n",
    "\n",
    "    # day2\n",
    "    ax.scatter(feature[20:23,0],feature[20:23,1], c='darkred', marker='x', label='pineapple day2', s=100)\n",
    "    ax.scatter(feature[23:26,0],feature[23:26,1], c='darkred',marker='o', label='potato chips day2', s=100)\n",
    "    ax.scatter(feature[26:29,0],feature[26:29,1],  c='darkblue',marker='^', label='salted plum day2', s=100)\n",
    "    ax.scatter(feature[29:,0],feature[29:,1], c='darkblue',marker='s', label='chocolate day2', s=100)\n",
    "    \n",
    "#     ax.legend(loc='upper right')\n",
    "    ax.grid(True)\n",
    "    if name != None:\n",
    "        fig.savefig(name, bbox_inch='tight')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = out.reshape(len(out), -1)\n",
    "\n",
    "#中間層の標準化\n",
    "ss = preprocessing.StandardScaler()\n",
    "print(out.shape)\n",
    "encode = ss.fit_transform(out)\n",
    "\n",
    "#umap\n",
    "umap_model = umap.UMAP(n_components=2, random_state=0)\n",
    "feature = umap_model.fit_transform(encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# render(ax, feature)\n",
    "render(ax, feature)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
